{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf9e831-e8e5-4c71-bbee-e117787eff48",
   "metadata": {},
   "source": [
    "# Проработка вариантов решения\n",
    "\n",
    "Задание:\n",
    "- проанализировать имеющиеся решения, обозначить плюсы и минусы каждого из потенциальных решений;\n",
    "- выбрать подходящее решение для нашей задачи и обосновать его;\n",
    "- соотнести ML-метрики с прокси-метриками и обосновать выбор;\n",
    "- сформировать обучающую выборку;\n",
    "- спроектировать схему валидации с учетом специфики задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c6b03-0cea-4312-a51d-30c660ab3467",
   "metadata": {},
   "source": [
    "# Анализ имеющихся решений\n",
    "\n",
    "Мы пойдем по следующему пути: проанализируем модели и алгоритмы в работах, которые пытались решить задачи категориальной классификации/продуктовой кластеризации/детекции товаров для взрослых в электронной коммерции. Статей в данной тематике много, поэтому ограничимся небольшой выборкой (всё-таки не научную работу проводим).\n",
    "\n",
    "## Ye Bi et al. (2017)\n",
    "Авторы участвовали в соревновании `SIGIR-2020`, где необходимо было провести классификацию товара (отнести к соответствующему номеру категории) используя заголовок, описание и изображение. Классы сильно несбалансированы.\n",
    "\n",
    "В работе в качестве ***кодировщика текста*** использовалась предобученная на большом корпусе французских текстов модель `CamemBERT` (необходимо было работать с текстами на французском). На вход модели подавался сконкатенированный текст заголовка и описания, разделенные при помощи тега `[SEP]`. Предобработка текста была достаточно простой: были удалены лишние пробелы и HTML-тэги. На выходе получался вектор размера 768 (base модель) или 1024 (large модель).\n",
    "\n",
    "В качестве ***кодировщика изображений*** использовалась модель `ResNet152`, предобученная на датасете `ImageNet`. Изображения вначале очищались от шума (удалялись пустые или одноцветные изображения, сломанные изображения) с помощью `cleanlab`. Дополнительно проводилась аугментация: добавлялись изображения с клипованием, кадрированием, вращением и  горизонтальным смещением. Изображения на вход подавались с разрешением (428 x 428).\n",
    "\n",
    "Слияние результатов работы кодировщиков проводилось с использованием двух схем: `feature-level fusion` и `decision-level fusion`. В первом случае вектора, полученные от каждого кодировщика, преобразуются в один вектор (конкатенацией, суммированием и т.п.), к полученному вектору затем применяется классификатор на основе полносвязной нейронной сети. Авторам не удалось построить удачную модель по данной схеме, все результаты были хуже, чем для текстового классификатора в отдельности. Вторая схема предполагает, что для каждого кодировщика имеется свой отдельный классификатор. На полученных данных затем сроится итоговая модель классификации. В данной работе `decision-level fusion` модель показала наилучшие результаты по метрике `Macro-F1`. Команда выиграла соревнование, заняв первое место на финальном лидерборде с результатом 0.914.\n",
    "\n",
    "![[DLS]](https://i.postimg.cc/4dDkWWq6/Bi-model.png)\n",
    "\n",
    "\n",
    "## Wirojwatanakul et al. (2019)\n",
    "Решалась задача категоризации товаров из Amazon. Выборка содержала 119073 товара, 90000 из которых использовались для обучения. Каждый товар в выборке мог быть отмечен метками нескольких категорий. Авторы провели следующую предобработку: удалили категории, в которых находилось менее 400 товаров. После этого, каждый товар в среднем имел 3 категории, максимальное и минимальное количество товаров на категорию были 37102 и 558, соответственно. Классы были сильно несбалансированы. \n",
    "\n",
    "Для оценки качества модели авторы использовали `micro-averaged F1` метрику, которая применима для классификации по нескольким меткам и для несбалансированных классов. В данной работе кодирование заголовка и описания проводилось по-отдельности:\n",
    "- ***Description classifier***: из описания удялялись стоп-слова, лишние пробелы, числа, пунктуация, и слова длиннее 30 символов. Описания усекались (дозаполнялись) до 300 слов. Классификатор имел следующую структуру: эмбеддинги получались при помощи GloVe (покрывал 61% словаря), сверточный слой (размер ядра 5, 200 фильтров), глобальный max pooling, полносвязный слой (170 нейронов, активация `ReLU`), полносвязный слой (122 нейрона, активация `sigmoid`). Результат на тесте - 77%. \n",
    "- ***Title classifier***: стоп-слова *не удалялись*, заголовок приводился к размеру в 57 слов. Нейронная сеть была аналогичной классификатору по описанию. Результат на тесте - 82.7%.\n",
    "- ***Image classifier***: предобученная на `ImageNet` модель `ResNet50`, адаптированная для классификации по 122 классам. При обучении первые слои замораживались, их веса не обновлялись (у авторов получилось, что оптимальным является 40 замороженных слоев). Результат на тесте - 61%.\n",
    "\n",
    "Среди унимодальных моделей лучшей оказалась `CNN`, обученная на заголовках.\n",
    "\n",
    "Перечисленные классификаторы были объединены по схеме `late fusion`. Авторы провели сравнение bi-modal fusion (image-description, image-title, description-title) и tri-modal fusion моделей. Результат по F1: 82%, 85%, 87% и 88.2%, соответственно. В качестве итогового классификатора использовалась трехслойная полносвязная нейронная сеть (200, 150 и 122 нейронов на слой; функции активации: `sigmoid`, `tanh`, `sigmoid`, соответственно).\n",
    "\n",
    "<img src=\"https://i.postimg.cc/J4WCJdbm/Wiroj-model.png\" width=\"550\">\n",
    "\n",
    "В заключении авторы в качестве замены `CNN` для классификации текста предлагают обратиться к `RNN` и трансформерам.\n",
    "\n",
    "\n",
    "## Ekansh Verma (2020)\n",
    "Авторы участвовали в том же соревновании, что и Ye Bi et al. (2018): *2020 SIGIR Workshop On eCommerce (ECOM20)*. Также как и в рассмотренной ранее работе, текст описания и текст заголова были объединены. Картинки приводились к размеру (224 x 224), нормализовались по каналу. Также проводилась аугментация схожим образом. Метрика качества - `Macro-F1`.\n",
    "\n",
    "Вначале в качестве baseline авторы обучили отдельно классификаторы только на текстовых данных и только на изображениях:\n",
    "- ***Image classifier***: в качестве кодировщика использовалась модель `SE-ResNeXt` c 50 слоями, предобученная на датасете `ImageNet`. Затем применялись адаптивный average pooling слой и линейный слой с числом нейронов, равным числу классов. Результат на валидационной части - 61.44%.\n",
    "- ***Text classifier***: `FlauBERT` или `CamemBERT` + классификатор, схожий с классификатором для изображений. Результат на валидационной части - 89.37% и 89.21% соответственно. \n",
    "\n",
    "Схема построения fusion модели представлена на картинке. Авторы использовали и `feature-level fusion` и `descion-level fusion` схемы: \n",
    "- `early fusion`: Выходы кодировщика изображений прогонялись через 1D сверточный слой, чтобы размер вектора был равен размерам векторов от `BERT` моделей. Вектора от каждой модели  конкатенировались в один (также был рассмотрен вариант сложения всех векторов). Схема представлена на картинке. Результат - около 90.5%.\n",
    "- `late fusion`: выходы классификаторов от трех моделей подавались на вход `LightGBM`, который проводил итоговую классификацию. Результат - 91.96%.\n",
    "\n",
    "Лучшей моделью оказалась `late fusion` с классификатором `LightGBM`. На итоговом лидерборде команда получила 90.53% и заняла третье место.\n",
    "\n",
    "<img src=\"https://i.postimg.cc/8kvV7Vft/Verma-model.png\" width=\"650\">\n",
    "\n",
    "\n",
    "\n",
    "## Shin et al. (2022)\n",
    "Авторы разработали фреймворк обучения, который согласовывает немаркированные языковые и визуальные представления продукта. Качество оценивалось в рамках задач категориальной классификации, извлечения атрибутов, сопоставления продуктов и распознавания продуктов для взрослых. Данные для работы брались из онлайн магазина NAVER. \n",
    "\n",
    "*Предобработка данных*: были удалены пары изображение-текст без картинок, с пустыми картинками, слишком маленькими изображениями и сломанными изображениями, с заголовками не относящимися к картинке, и с заголовками, в которых менее двух токенов. Дубликаты по заголовкам и по картинкам также удалялись. Исключались из рассмотрения неправильно промаркированные товары \"для взрослых\", где, например, часть изображения была заблюрена а is_adult=False. Итоговый датасет содержал 270М продуктов, 41К использовались в качестве тестовых данных.\n",
    "\n",
    "![[Shin]](https://i.postimg.cc/KjtXwnhd/Shin-model.png)\n",
    "\n",
    "- ***Image encoder***: ViT-B/32 трансформер. По сравнению с CNN требует меньше времени на обучение и меньше GPU в мультимодальных предобученных задачах с двумя энкодерами.\n",
    "- ***Text encoder***: многоязычная BERT модель.\n",
    "\n",
    "Кодировщики обучаются совместно с использованием `symmetric cross-entropy loss` за счет максимизации косинусной схожести эмбеддингов пар текст-изображений, относящихся к одному товару, и минимизации схожести для пар, относящихся разным товарам. В каждом батче при обучении не должно быть дубликатов.\n",
    "\n",
    "Оценка проводилась с использованием трех подходов:\n",
    "1. `zero-shot-transfer` - для каждого названия класса получают эмбеддинги, которые затем сравниваются с усредненными эмбеддингами от пар текст-картинка. В итоге для каждой интересующей можно найти наиболее вероятный класс, к которому она принадлежит.\n",
    "2. `linear probe` - обученная модель замораживается, обучается только линейный классификатор, построенный на получаемых эмбеддингах от пар текст-картинка.\n",
    "3. `fine-tuning` - помимо линейного классификатора, энкодеры дополнительно дообучаются.\n",
    "\n",
    "**Задача: кластеризация**<br>\n",
    "размерность полученных мультимодальных эмбеддингов понижалась до 128 с помощью `PCA`, затем кластеризация проводилась с использованием алгоритма `k-means`. Оценка кластеров проводилась с использованием метрик *точность кластеризации* `ACC`, *нормализованной взаимной информации* `NMI` и *скорректированного индекса Рэнда* `ARI`.\n",
    "\n",
    "**Задача: категориальная классификация**<br>\n",
    "оценка категориальной классификации проводилась по трем датасетам: со всеми категориями, модные товары, товары для детей. Количество продуктов в каждой категории нормализовалось. Метрика - `accuracy`.\n",
    "\n",
    "**Задача: распознование товаров для взрослых**<br>\n",
    "тренировочные данные: 10К товаров для взрослых и 50К обычных товаров. Тестовые: 1К к 5К. Метрика - `F1-score`.\n",
    "\n",
    "Согласно приведенным в статье результатам, предложенная авторами модель превосходит стандартные методы CLIP, KELIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f261a5-4611-4474-9829-3a140d9a3ea7",
   "metadata": {},
   "source": [
    "# Выбор модели и её обоснование "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72697335-8ca8-49fb-b50a-770638a2773a",
   "metadata": {},
   "source": [
    "Основные требования к модели:\n",
    "- Кодировщик текстового описания:\n",
    "    - русскоязычность/мультиязычность;\n",
    "    - размер входного текста: не менее 200 токенов (среднее число слов в описании - 200);\n",
    "    - предобучен на большом корпусе русских текстов;\n",
    "- Кодировщик изображения:\n",
    "    - разрешение картинки при подаче на вход кодировщику должно быть относительно большим;\n",
    "    - предобучен на большом количестве изображений;\n",
    "- Для всей мультимодальной модели:\n",
    "    - должна обучаться на немаркированных данных, только с использованием пары текст-изображение;\n",
    "    - должна обучаться на доступных ресурсах (kaggle, colab) за адекватное время (~ час);\n",
    "    - должна быть легкодоступной (на PyTorch или Huggingface).\n",
    "\n",
    "Для обучения на немаркированных данных будем использовать `contrastive learning`, который используется в `CLIP`. Имеется модель `ruCLIP`, которая работает с русским текстом, однако контекстное окно у нее совсем небольшое - 77 токенов. Необходимо подобрать каждый энкодер самостоятельно.\n",
    "\n",
    "Попытки сравнить энкодеры по качеству и производительности проводились неоднократно. Для энкодеров, которые могут работать с русским текстом, составлен неплохой рейтинг [здесь](https://github.com/avidale/encodechka?tab=readme-ov-file), который складывался из мреднего качетсва работы, скорости работы на CPU и GPU, а также занимаемой памяти. Для решения нашей задачи могут подойти следующие варианты:\n",
    "- `rubert-tiny2` (2048)\n",
    "- `LaBSE-en-ru` (256)\n",
    "- `MUSE-3`\n",
    "\n",
    "В качетве кодировщика изображений можно использовать:\n",
    "- `EfficientNet-B3` (300 x 300)\n",
    "- `ViT-B/32` (224 x 224)\n",
    "- `ResNet-152` (224 x 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549112c7-8488-480b-bd61-b4849185db22",
   "metadata": {},
   "source": [
    "# Метрики\n",
    "\n",
    "## Задача кластеризации\n",
    "\n",
    "Ранжирование товаров по степени схожести.\n",
    "\n",
    "- *adjusted mutual information* `AMI`: скорректированная взаимная информация. Интуитивно, взаимная информация `MI` измеряет долю информации, общей для обоих разбиений: насколько информация об одном из них уменьшает неопределенность относительно другого. `AMI` позволяет избавиться от роста индекса `MI` с увеличением числа классов. Принимает значения в области $[0, 1]$. Значения, близкие к нулю, говорят о независимости разбиений, а близкие к единице – об их схожести. Для расчета необходимы истинные метки.\n",
    "- *гомогенность*, *полнота* и *V-мера*: гомогенность измеряет, насколько каждый кластер состоит из объектов одного класса, а полнота — насколько объекты одного класса относятся к одному кластеру. V-мера - гармоническое среднее гомогенности и полноты.\n",
    "- *Силуэт*: подходит для оценки качества кластеризации как таковой, без какой-либо информации об истинных классах.\n",
    "\n",
    "## Задача категориальной классификации\n",
    "\n",
    "Отнесение товара к категории, подкатегории. Для одежды отнесение к сезонности товара. Для какого пола товар предназначен и какие имеются возрастные ограничения.\n",
    "\n",
    "- `macro-F1`: для каждого класса по отдельности рассчитывается `F1`, затем берется среднее арифметическое всех полученных значений;\n",
    "- `weighted-averaged-F1`: также для каждого класса рассчитывается `F1`, затем берется среднее взвешенное. Веса берутся на основе истинного распределения элементов по классам;\n",
    "- `accuracy` или `micro-F1`: для каждого класса рассчитываются `TP`, `FP`, `FN`, затем данные значения складываются и итоговое значение `micro-F1` рассчитывается по формуле: $TP/(TP+0.5(FP+FN))$. То же самое значение получится и для `accuracy`. Подходит только для сбалансированных выборок.\n",
    "\n",
    "## Задача бинарной классификации\n",
    "\n",
    "Является ли товар товаром для взрослых. Является ли товар хрупким.\n",
    "\n",
    "- Стандартный `F1-score`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861ecc6-4704-4a3d-9c8a-d0728fbdb086",
   "metadata": {},
   "source": [
    "# Формирование обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a758f7-ae5b-47a4-b7d8-10c5a69b9cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sergei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import swifter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# сделаем возможным параллельную обработку строковых колонок в pd.DataFrame\n",
    "swifter.set_defaults(\n",
    "    allow_dask_on_strings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c76ba5-4bb3-4877-85f7-5d4f11b049ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка текста в заголовке и описании\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, max_word_len=15, title_size=60, description_size=300):\n",
    "        self.title_size = title_size\n",
    "        self.description_size = description_size\n",
    "        self.max_word_len = max_word_len\n",
    "        \n",
    "        units = ['мг', 'г', 'гр', 'кг', 'мл', 'л', 'мм', 'см', 'м', 'км', 'шт', 'штук']\n",
    "        stop_words = stopwords.words('russian')\n",
    "        \n",
    "        # часть из стоп-слов оставим\n",
    "        stop_words.remove('не')\n",
    "        stop_words.remove('для')\n",
    "        \n",
    "        self.title_exclude_list = list(string.punctuation) + units\n",
    "        self.description_exclude_list = self.title_exclude_list + stop_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, get_characteristics=True):\n",
    "        X = X.copy()\n",
    "        \n",
    "        X['title'] = X['title'].swifter.progress_bar(desc='Title process').apply(lambda x: self._process_text(x, 'title'))\n",
    "        X['description'] = X['description'].swifter.progress_bar(desc='Description process').apply(lambda x: self._process_text(x, 'description'))\n",
    "        \n",
    "        if get_characteristics:\n",
    "            X['characteristics'] = X['characteristics'].progress_apply(lambda x: self._process_characteristics(x))\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def _process_text(self, text: str, text_type: str) -> str:\n",
    "        \n",
    "        if text_type == 'title':\n",
    "            exclude_list = self.title_exclude_list\n",
    "            size = self.title_size\n",
    "            \n",
    "        elif text_type == 'description':\n",
    "            exclude_list = self.description_exclude_list\n",
    "            size = self.description_size\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('text_type must be \\'title\\' or \\'description\\'')\n",
    "        \n",
    "        # удаляем сочетания `<число> x <число>` и `<число><единица измерения>`\n",
    "        text = re.sub(r'\\d+[хХxX]\\d+|\\d+[кмглршт]+|\\d+ [xXхХ] \\d+', '', text)\n",
    "            \n",
    "        return ' '.join([word for word in word_tokenize(text.lower()) if word not in exclude_list and \n",
    "                                                                      not word.isdigit() and\n",
    "                                                                      len(word) <= self.max_word_len][:size])\n",
    "    \n",
    "    def _process_characteristics(self, text: str) -> list[dict]:\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "        # первый паттерн\n",
    "        if '\\'b\\\\\\'' in text:\n",
    "            return eval(re.sub(r'\\\\+', r'\\\\', text)[5:-3].replace('true', 'True').replace('false', 'False'))\n",
    "\n",
    "        # второй паттерн\n",
    "        text = text.replace(\"}\\n\", \"},\")\n",
    "        text = re.sub(r'\\n\\s+', ' ', text)\n",
    "        text = re.sub(r'array', 'np.array', text)\n",
    "\n",
    "        return eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e339e39a-ab8f-4779-ac80-6bd686310843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечение характеристик\n",
    "class CharExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, char_names: list = None, col_names: list = None):\n",
    "        if char_names is None and col_names is None:\n",
    "            self.char_names = ['Пол', 'Возрастные ограничения', 'Сезон', 'Хрупкость']\n",
    "            self.col_names = ['sex', 'age_restrictions', 'season', 'fragility']\n",
    "            \n",
    "        elif char_names is None or col_names is None:\n",
    "            raise ValueError('Both char_names and col_names must be provided')\n",
    "            \n",
    "        else:\n",
    "            self.char_names = char_names\n",
    "            self.col_names = col_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[self.col_names] = pd.DataFrame(X['characteristics'].swifter.apply(lambda x: self._get_characteristic(x)).tolist(), \n",
    "                                         columns=self.char_names, index=X.index)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def _get_characteristic(self, char_list: list[dict]) -> float|list[float]:\n",
    "        res = [np.nan] * len(self.char_names)\n",
    "\n",
    "        for char in char_list:\n",
    "            \n",
    "            if char['charcName'] in self.char_names:\n",
    "\n",
    "                if 'value' in char and char['value'] is not None:\n",
    "                    if isinstance(char['value'], str):\n",
    "                        char['value'] = float(char['value'].replace(',', '.'))\n",
    "\n",
    "                    res[self.char_names.index(char['charcName'])] = char['value']\n",
    "\n",
    "                if 'charcValues' in char and char['charcValues'] is not None:\n",
    "                    if len(char['charcValues']) == 1:\n",
    "                        res[self.char_names.index(char['charcName'])] = char['charcValues'][0]\n",
    "                    else:\n",
    "                        res[self.char_names.index(char['charcName'])] = list(char['charcValues'])\n",
    "                    \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50527fe6-df49-4cbe-aec2-ffd718b3ccc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_df = pd.read_parquet('image_df.parquet')\n",
    "\n",
    "# фильтр для пустых изображений\n",
    "empty_nms = image_df[image_df['size'] < 25 * 1024].nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a7607a-f2cb-483a-904e-0f502f26adc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_files = 'D:/HorizontalML/'\n",
    "path_to_zip = path_to_files + 'wb_school_horizcv_images.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7b790d-d2f1-4ff0-b90c-b1f26035f2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df, cols_to_drop=['brand', 'price']):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df.loc[df.title == '', 'title'] = np.nan\n",
    "    df.loc[df.description == '', 'description'] = np.nan\n",
    "    \n",
    "    # удаляем товары, где нет названия и описания\n",
    "    df = df[df[['title', 'description']].notna().all(axis=1)]\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # заполняем пропуски в описаниях заголовком, где это возможно\n",
    "    df['description'] = df.description.fillna(df.title)\n",
    "    \n",
    "    # заполням пропуски в заголовках первыми 10 словами из описания\n",
    "    df['title'] = df['title'].fillna(df['description'].str.split().str[:10].str.join(' '))\n",
    "    \n",
    "    # исключаем товары с пустыми картинками\n",
    "    df = df[~df.nm.isin(empty_nms)]\n",
    "    \n",
    "    # удалим товары, заголовок которых состоит менее чем из 2х символов\n",
    "    df = df[df['title'].str.len() > 2]\n",
    "    \n",
    "    # удаляем колонки, которые не будут использованы\n",
    "    for col in df.columns:\n",
    "        if col in cols_to_drop:\n",
    "            df = df.drop(col, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ee2aa2-503d-4d28-b9e6-cdebba76d79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = clean_dataset(pd.read_parquet(path_to_files + 'wb_school_train.parquet'))\n",
    "test = clean_dataset(pd.read_parquet(path_to_files + 'wb_school_test.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a451af47-996e-4b0a-bd28-d3bf6722c098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2adcb2b57b64a31a115c489b716588e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Title process:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c841f409be9348b8b12adb87e2707cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Description process:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e35115d49b4a188c687411c1ae8ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e554f8a09f3e4c14aeb0b26f23d5b357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/98660 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe9d3e3ec72479f8ca066c3703ba64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Title process:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4574a1ff532842d6a68f210accf63400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Description process:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "char_extractor = CharExtractor()\n",
    "\n",
    "train = char_extractor.transform(preprocessor.transform(train))\n",
    "test = preprocessor.transform(test, get_characteristics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc296cf-b3c2-4fec-866f-2709695559c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[train.description == '', 'description'] = train.loc[train.description == '', 'title']\n",
    "train.loc[train.title == '', 'title'] = train.loc[train.title == '', 'description'].apply(lambda x: ' '.join(x.split()[:7]))\n",
    "\n",
    "test.loc[test.description == '', 'description'] = test.loc[test.description == '', 'title']\n",
    "test.loc[test.title == '', 'title'] = test.loc[test.title == '', 'description'].apply(lambda x: ' '.join(x.split()[:7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d38c8e-5475-4392-b783-ee8fe0c01cbe",
   "metadata": {},
   "source": [
    "## Возрастные ограничения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0624f905-22d7-4cfb-b15e-221d2609eff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_age_restrictions(ar):\n",
    "    if ar in ['0+', '0 +']:\n",
    "        return np.nan\n",
    "    \n",
    "    ar = ar.lower()\n",
    "    \n",
    "    if re.findall(r'без огран|нет огран|для всех|любо[йг]', ar):\n",
    "        return 'для всех возрастов'\n",
    "    \n",
    "    if re.findall(r'мес|годик|рожден|малыш|реб[её]н', ar):\n",
    "        return 'для малышей'\n",
    "    \n",
    "    nums = sorted(re.findall(r'\\d+', ar))\n",
    "    \n",
    "    if nums:\n",
    "        num = int(nums[0])\n",
    "        if num >= 18:\n",
    "            return 'для взрослых'\n",
    "        elif 12 <= num < 18:\n",
    "            return 'для подростков'\n",
    "        elif 3 <= num < 12:\n",
    "            return 'для детей'\n",
    "        else:\n",
    "            return 'для малышей'\n",
    "        \n",
    "    if re.findall(r'дет[ямскей]{2}|школ|девоч|мальчик', ar):\n",
    "        return 'для детей'\n",
    "    \n",
    "    if re.findall(r'мужч|женщ|взросл', ar):\n",
    "        return 'для взрослых'\n",
    "    \n",
    "    if re.findall(r'подрост', ar):\n",
    "        return 'для подростков'\n",
    "        \n",
    "    return 'для всех возрастов'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fabab1da-5db1-4b92-8960-418dbab51ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['age_restrictions'] = train.age_restrictions.apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "train.age_restrictions = train.age_restrictions.dropna().apply(get_age_restrictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5174317b-1c36-4210-831a-f3567c36161f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "для детей             1910\n",
       "для подростков         882\n",
       "для малышей            632\n",
       "для взрослых           316\n",
       "для всех возрастов     165\n",
       "Name: age_restrictions, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age_restrictions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c7622-f182-451f-94a7-843c0a1fabd1",
   "metadata": {},
   "source": [
    "## Пол"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb9b7c-8579-4fbe-b2cf-7466a882b0f5",
   "metadata": {},
   "source": [
    "Классификация по половым признакам:\n",
    "- Мужская\n",
    "    - мужская\n",
    "    - для мальчиков\n",
    "- Женская\n",
    "    - женская\n",
    "    - для девочек\n",
    "- Унисекс\n",
    "- Детская\n",
    "\n",
    "Исходя из этой классификации, оставим вариант с \"Мужская\", \"Женская\" и \"Детская\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09498ba8-92ca-4d42-b6f6-f2877b22cc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "для женщин       10614\n",
       "для детей         4597\n",
       "для мужчин        3672\n",
       "для девочек       2379\n",
       "для мальчиков     1226\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sex = train.sex.replace(['детский', 'Women'], ['Детский', 'Женский'])\n",
    "train['sex'] = train.sex.replace(['Детский', 'Женский', 'Девочки', 'Мужской', 'Мальчики'], \n",
    "                                 ['для детей', 'для женщин', 'для девочек', 'для мужчин', 'для мальчиков'])\n",
    "train.sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dec076-c93d-4633-8663-6947f6d9caef",
   "metadata": {},
   "source": [
    "## Сезонность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "451eb06c-94ce-4645-8187-87a17f340728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_from_list(x: list[str]|str, \n",
    "                  params_seq: list[str]) -> float|int|str:\n",
    "    \"\"\"\n",
    "    Обработка характеристик, где встречается несколько значения списком.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(x, list):\n",
    "        for param in params_seq:\n",
    "            if param in x:\n",
    "                return param\n",
    "            return x[0]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d1b9845-e727-43ec-9b43-0c0251bb1d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "круглогодичный    3193\n",
       "лето              2574\n",
       "демисезон         2318\n",
       "зима              1829\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.season = train.season.apply(lambda x: get_from_list(x, ['лето', 'зима', 'демисезон', 'круглогодичный']))\n",
    "train.season.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9dc33c-0cd3-4a99-b3cd-e7be264f123f",
   "metadata": {},
   "source": [
    "## Хрупкость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c808a7da-5fc4-4937-90ce-fa925cdfe758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fragility(x):\n",
    "    if x is None:\n",
    "        return 'не указано'\n",
    "    \n",
    "    if re.match(r'не х[рупкое]+|нет|прочн|над[её]ж', x) is not None:\n",
    "        return 'не хрупкий'\n",
    "    elif re.match(r'х[рупкое]+|да|не брос', x) is not None:\n",
    "        return 'хрупкий'\n",
    "    else:\n",
    "        return 'не хрупкий'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ceb1502-3d40-4de2-acd7-6bcf3aa55c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "не хрупкий    4773\n",
       "хрупкий       2681\n",
       "Name: fragility, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragility = train[train.fragility.apply(type) != list].fragility.dropna()\n",
    "fragility = fragility.apply(get_fragility)\n",
    "\n",
    "fragility_lists = train[train.fragility.apply(type) == list].fragility\n",
    "# обрабатываем списки, если встречается оба варианта - исключаем из рассмотрения\n",
    "fragility_lists = fragility_lists.apply(lambda x: set([get_fragility(i) for i in x])).apply(lambda x: list(x)[0] if len(x) == 1 else None)\n",
    "\n",
    "train['fragility'] = fragility\n",
    "\n",
    "train['fragility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "459f8527-17ed-4ec2-8c6e-d4e9e12e484c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['sex'] = train['sex'].astype('category')\n",
    "train['age_restrictions'] = train['age_restrictions'].astype('category')\n",
    "train['season'] = train['season'].astype('category')\n",
    "train['fragility'] = train['fragility'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "771a9d2f-46e1-45e1-b012-c6b5f4877443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[['sex', 'age_restrictions', 'season', 'fragility']].to_csv('chars_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f204bdb0-9daa-4f24-bf3b-31137aaac354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_parquet('train_preprocessed.parquet', index=False)\n",
    "test.to_parquet('test_preprocessed.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49882490-7468-4ba4-a6e0-e0d4abc6eba8",
   "metadata": {},
   "source": [
    "# Схема валидации\n",
    "\n",
    "Обучение на первом этапе происходит с использованием `contrastive learning`: косинусная схожесть векторных представлений текста и изображения для одного товара увеличивается, а для пар от разных товаров - уменьшается.\n",
    "\n",
    "## Кластеризация\n",
    "1. Снижение размерности векторов получаемых эмбеддингов изображений и текста: `PCA`, `UMAP` или `t-SNE`;\n",
    "2. Кластеризация: `KMeans`, `HDBSCAN`;\n",
    "3. Улучшение метрики *Силуэта*;\n",
    "4. Проверка, относит ли к одному и тому же кластеру вектора картинок товаров, для которых заголовок и описание (или по-отдельности) полностью совпадают;\n",
    "5. Расчет метрик `AMI` и V-меры для известных категорий товаров.\n",
    "\n",
    "## Классификация\n",
    "1. Данные: извлеченные из характеристик в train датасете возрастные ограничения, сезонность, хрупкость, пол. Разеляются на train и valid части.\n",
    "2. Построение классификаторов только на основе текста или только на основе изображения. Получение метрик для унимодальных классификаторов. В зависимости от числа классов используется либо `wheighted-averaged-F1` либо `F1` метрика.;\n",
    "3. На основе двух энкодеров строится `fusion` модель для классификации. Обучается на train части, тестируется на valid части. Результат сравнивается с унимодальными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f3242-2348-4709-9f60-d54b9bc38be7",
   "metadata": {},
   "source": [
    "# Литература:\n",
    "- [Ye Bi et al. (2017) A Multimodal Late Fusion Model for E-Commerce Product Classification](https://arxiv.org/pdf/2008.06179.pdf)\n",
    "- [Pasawee Wirojwatanakul et al. (2019) Multi-Label Product Categorization Using Multi-Modal Fusion Models](https://arxiv.org/abs/1907.00420)\n",
    "- [Ekansh Verma (2020) Deep Multi-level Boosted Fusion Learning Framework for Multi-modal Product Classification](https://sigir-ecom.github.io/ecom20DCPapers/SIGIR_eCom20_DC_paper_8.pdf)\n",
    "- [Wonyoung Shin (2022) e-CLIP: Large-Scale Vision-Language Representation Learning in E-commerce](https://arxiv.org/abs/2207.00208)\n",
    "- [Нейронная Сеть CLIP от OpenAI: Классификатор, который не нужно обучать. Да здравствует Обучение без Обучения | Хабр](https://habr.com/ru/articles/539312/)\n",
    "- [ruCLIP — мультимодальная модель для русского языка | Хабр](https://habr.com/ru/companies/sberdevices/articles/564440/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
